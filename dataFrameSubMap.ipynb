{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "#19년 20년 월별 데이터 생성\n",
    "data2019 = {}\n",
    "data2020 = {}\n",
    "\n",
    "class subWayData:\n",
    "    def __init__(self,dataY):\n",
    "        pass\n",
    "    def create_data(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "for indx,csvF in enumerate(os.listdir('./seoul_subway_data/2019')):\n",
    "    #19년도 데이터 안에 이미 데이터가 있으면 넘어가고 없으면 기본값으로 추가\n",
    "    if not 'data' + csvF[-10:-4] in data2019.keys():\n",
    "        data2019.setdefault('data' + csvF[-10:-4])\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        data = pd.read_csv('./seoul_subway_data/2019/' + csvF,encoding = 'UTF-8')\n",
    "    except:\n",
    "        data = pd.read_csv('./seoul_subway_data/2019/' + csvF,encoding = 'EUC-KR')\n",
    "    data2019['data' + csvF[-10:-4]] = data\n",
    "\n",
    "for indx,csvF in enumerate(os.listdir('./seoul_subway_data/2020')):\n",
    "    #20년도 데이터 안에 이미 데이터가 있으면 넘어가고 없으면 기본값으로 추가\n",
    "    if not 'data' + csvF[-10:-4] in data2020.keys():\n",
    "        data2020.setdefault('data' + csvF[-10:-4])\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    #인코딩 부분에서 문제가 있는 경우가 있어서 기본값 utf-8로 처리에 에러가 있을경우 euc-kr로 대체\n",
    "    try:\n",
    "        data = pd.read_csv('./seoul_subway_data/2020/' + csvF,encoding = 'UTF-8')\n",
    "    except:\n",
    "        data = pd.read_csv('./seoul_subway_data/2020/' + csvF,encoding = 'EUC-KR')\n",
    "    data2020['data' + csvF[-10:-4]] = data\n",
    "\n",
    "#2019년 데이터에서 불필요한 데이터 조정\n",
    "for dataY in data2019.keys():\n",
    "    if '역ID' in data2019[dataY].columns:\n",
    "        data2019[dataY].drop('등록일자',axis=1,inplace = True)\n",
    "        data2019[dataY].rename(columns = {'하차총승객수' : '등록일자'},inplace = True)\n",
    "        data2019[dataY].rename(columns = {'승차총승객수' : '하차총승객수'},inplace = True)\n",
    "        data2019[dataY].rename(columns = {'역명' : '승차총승객수'},inplace = True)\n",
    "        data2019[dataY].rename(columns = {'역ID' : '역명'},inplace = True)\n",
    "    else:\n",
    "        data2019[dataY].dropna(inplace=True)\n",
    "\n",
    "#2020년 데이터에서 불필요한 데이터 조정\n",
    "for dataY in data2020.keys():\n",
    "    if '역ID' in data2020[dataY].columns:\n",
    "        data2020[dataY].drop('등록일자',axis=1,inplace = True)\n",
    "        data2020[dataY].rename(columns = {'하차총승객수' : '등록일자'},inplace = True)\n",
    "        data2020[dataY].rename(columns = {'승차총승객수' : '하차총승객수'},inplace = True)\n",
    "        data2020[dataY].rename(columns = {'역명' : '승차총승객수'},inplace = True)\n",
    "        data2020[dataY].rename(columns = {'역ID' : '역명'},inplace = True)\n",
    "    else:\n",
    "        data2020[dataY].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>데이터 정리 최종</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os, csv\n",
    "\n",
    "option = webdriver.ChromeOptions()\n",
    "option.add_argument('headless')\n",
    "\n",
    "driver = webdriver.Chrome('/Users/sanengr/Downloads/chromedriver',options=option)\n",
    "driver.get('https://gits.gg.go.kr/gtdb/web/trafficDb/railRoad/TransitSWPass.do')\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "def setRadio():\n",
    "    driver.find_element_by_xpath('//*[@id=\"radio1\"]').click()\n",
    "\n",
    "def setSelect1(sel1):\n",
    "    driver.find_element_by_xpath(\"//select[@name='select1']/option[text()='%s']\" %sel1).click()\n",
    "    \n",
    "def setSelect2(sel2):\n",
    "    driver.find_element_by_xpath(\"//select[@name='select2']/option[text()='%s']\" %sel2).click()\n",
    "\n",
    "#soup로 고정된 html 값에서 radio1 버튼 찾아와서 클릭하기\n",
    "setRadio()\n",
    "\n",
    "#rad 버튼 클릭후 동적으로 변경된 웹페이지에서 select1아이디 값 가져오기\n",
    "select1 = driver.find_element_by_id('select1')\n",
    "t_sel1 = select1.text.split('\\n')\n",
    "sel1 = []\n",
    "for i,t in enumerate(t_sel1):\n",
    "    if not t.strip() == '':\n",
    "        sel1.append(t.strip())\n",
    "\n",
    "#시 - 역명 넣을 csv파일 생상(기존에 있는건 삭제)\n",
    "if os.path.exists('./seoul_subway_data/구_역명.csv'):\n",
    "    os.remove('./seoul_subway_data/구_역명.csv')\n",
    "\n",
    "with open('./seoul_subway_data/구_역명.csv','w') as csvFile:\n",
    "    writer = csv.DictWriter(csvFile,fieldnames=['구','역명'])    \n",
    "    writer.writeheader()\n",
    "    \n",
    "#sel1 값을 넣은 후 sel2값 넣고 검색 후 list값들을 가져온 다음 데이터 정리\n",
    "for i in sel1:\n",
    "    setSelect1(i)\n",
    "    \n",
    "    sel2 = driver.find_element_by_id('select2')\n",
    "    t_sel2 = sel2.text.split('\\n')\n",
    "    for a in range(len(t_sel2)):\n",
    "        t_sel2[a] = t_sel2[a].strip()\n",
    "        #전체 선택 혹은 비어있는 경우는 넘어가기 (행정 구역만 필요하니까)\n",
    "        if '전체선택' == t_sel2[a] or '' == t_sel2[a]:\n",
    "            continue\n",
    "        \n",
    "        setSelect2(t_sel2[a])\n",
    "        driver.find_element_by_xpath('//*[@id = \"search\"]').click()\n",
    "        li_loc = (driver.find_element_by_id('selList')).text.split('\\n')\n",
    "\n",
    "        for i in li_loc:\n",
    "            #가져온 list값은 매봉(1호선) 이런식으로 돼있으므로 ()를 기준으로 역이름과 호선명 나눠주기\n",
    "            st_idx = i.find('(') + 1\n",
    "            f_idx = i.find(')')\n",
    "            t_sel2[a] = t_sel2[a].replace('_','')\n",
    "            #csv파일에 바로 넣기\n",
    "            with open('./seoul_subway_data/구_역명.csv','a') as csvFile:\n",
    "                writer = csv.DictWriter(csvFile,fieldnames=['구','역명'])\n",
    "                writer.writerow({'구':t_sel2[a],'역명':i[:st_idx-1]})\n",
    "\n",
    "gu_sta_name = pd.read_csv('./seoul_subway_data/구_역명.csv')\n",
    "\n",
    "#2019년 데이터에 구 추가\n",
    "for dataY in data2019.keys():\n",
    "    if not '구' in data2019[dataY].columns:    \n",
    "        data2019[dataY] = pd.merge(data2019[dataY],gu_sta_name,on='역명',how = 'inner')\n",
    "\n",
    "        if True in data2019[dataY].duplicated():\n",
    "            data2019[dataY] = data2019[dataY].drop_duplicates()\n",
    "            data2019[dataY].reset_index(inplace=True)\n",
    "        if 'index' in data2019[dataY].columns:\n",
    "            data2019[dataY].drop(columns='index',inplace=True)\n",
    "    \n",
    "#2020년 데이터에 구 추가    \n",
    "for dataY in data2020.keys():\n",
    "    if not '구' in data2020[dataY].columns:    \n",
    "        data2020[dataY] = pd.merge(data2020[dataY],gu_sta_name,on='역명',how = 'inner')\n",
    "\n",
    "        if True in data2020[dataY].duplicated():\n",
    "            data2020[dataY] = data2020[dataY].drop_duplicates()\n",
    "            data2020[dataY].reset_index(inplace=True)\n",
    "        if 'index' in data2020[dataY].columns:\n",
    "            data2020[dataY].drop(columns='index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import folium\n",
    "\n",
    "# geo_path = '/Users/sanengr/Downloads/python/tmp/southkorea-maps/kostat/2018/json/skorea-municipalities-2018-geo.json'\n",
    "# geo_str = json.load(open(geo_path, encoding='utf-8'))\n",
    "\n",
    "# map = folium.Map(location=[37.5502, 126.982], zoom_start=11,\n",
    "#                 tiles='stamentoner')\n",
    "# map.choropleth(geo_data=geo_str)\n",
    "\n",
    "# print(geo_str.keys())\n",
    "# print(geo_str['features'][0].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>그냥 바로 해버리면 전국에 칠해지니까 서울지역으로 json 범위 축소 </h1><br><p>근데 왜 한번에 안되고 여러번에 거쳐야 되는지는 모르겠음...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json 처리 전 지역 수 :  250\n",
      "json 처리 후 지역 수 :  25\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 13901 to array axis with dimension 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-73b9bb27bbd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mmap2019\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mmap2019\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mmap2019\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-73b9bb27bbd6>\u001b[0m in \u001b[0;36mdrawMap\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdrawMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#맵 그려주기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         folium.Choropleth(\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mgeo_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeo_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/js_env/lib/python3.8/site-packages/folium/features.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, geo_data, data, columns, key_on, bins, fill_color, nan_fill_color, fill_opacity, nan_fill_opacity, line_color, line_weight, line_opacity, name, legend_name, overlay, control, show, topojson, smooth_factor, highlight, **kwargs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey_on\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mreal_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m             \u001b[0mreal_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 13901 to array axis with dimension 7"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import folium\n",
    "\n",
    "geo_path = './map/skorea-municipalities-2018-geo.json'\n",
    "geo_str = json.load(open(geo_path, encoding='utf-8'))\n",
    "\n",
    "#json 데이터 안다듬어주면 전국단위로 난리남\n",
    "print('json 처리 전 지역 수 : ',len(geo_str['features']))\n",
    "min_len_geoStr = False\n",
    "k = [-1,-2]\n",
    "#서울 지역 코드 값 = 1로 시작\n",
    "#왜인지는 모르겠는데 한번에 처리가 안되서 이전 카운트 개수하고 현재 카운트 개수에 차이가 없을 때 break\n",
    "while min_len_geoStr == False:\n",
    "    if k[0] == k[1]:\n",
    "        min_len_geoStr = True\n",
    "    k[0] = len(geo_str['features'])\n",
    "    for i,t in enumerate(geo_str['features']):\n",
    "        if not t['properties']['code'][0] == '1':\n",
    "            del geo_str['features'][i]\n",
    "    k[1] = len(geo_str['features'])        \n",
    "\n",
    "print('json 처리 후 지역 수 : ',len(geo_str['features']))\n",
    "\n",
    "class mapping:\n",
    "    global geo_str\n",
    "    \n",
    "    def __init__(self,dataY):\n",
    "        self.map = folium.Map(location=[37.5502, 126.982], zoom_start=11,\n",
    "                    tiles='stamentoner')\n",
    "        \n",
    "        self.dataY = dataY\n",
    "\n",
    "\n",
    "    def drawMap(self):\n",
    "        #맵 그려주기\n",
    "        folium.Choropleth(\n",
    "            geo_data=geo_str,\n",
    "            data=self.dataY, \n",
    "            columns=['구','승차총승객수'], \n",
    "            key_on='feature.properties.name',\n",
    "            fill_color='PuRd',\n",
    "            legend_name='지하철 유동인구 수'\n",
    "        ).add_to(self.map)\n",
    "\n",
    "    def saveMap(self,YM):\n",
    "        YM = str(YM)\n",
    "        \n",
    "        #쥬피터에서 보여주면 한글 깨져서 동일 경로 map 디렉토리에 해당 맵을 만들어줌\n",
    "        if os.path.exists('./map'):\n",
    "            if os.path.exists('./map/{}.html'.format(YM)):\n",
    "                os.remove('./map/{}.html'.format(YM))\n",
    "        else:\n",
    "            os.makedirs('./map')\n",
    "        self.map.save('./map/{}.html'.format(YM))\n",
    "        \n",
    "map2019 = mapping(data2019)\n",
    "map2019.drawMap()\n",
    "map2019.saveMap(2019)\n",
    "\n",
    "map2020 = mapping(data2020)\n",
    "map2020.drawMap()\n",
    "map2020.saveMap(2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = data2020[['노선명','역명','승차총승객수','하차총승객수','구']][data2020['승차총승객수'] - data2020['하차총승객수'] > 3000]\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "#19년 20년 월별 데이터 생성\n",
    "data2019 = {}\n",
    "data2020 = {}\n",
    "\n",
    "class subWayData:\n",
    "    def __init__(self,year):\n",
    "        self.year = year\n",
    "    \n",
    "    def create_data(self):\n",
    "        pass\n",
    "    \n",
    "for indx,csvF in enumerate(os.listdir('./seoul_subway_data/{}'.format(year))):\n",
    "    #19년도 데이터 안에 이미 데이터가 있으면 넘어가고 없으면 기본값으로 추가\n",
    "    if not 'data' + csvF[-10:-4] in data2019.keys():\n",
    "        data2019.setdefault('data' + csvF[-10:-4])\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        data = pd.read_csv('./seoul_subway_data/2019/' + csvF,encoding = 'UTF-8')\n",
    "    except:\n",
    "        data = pd.read_csv('./seoul_subway_data/2019/' + csvF,encoding = 'EUC-KR')\n",
    "    data2019['data' + csvF[-10:-4]] = data\n",
    "\n",
    "for indx,csvF in enumerate(os.listdir('./seoul_subway_data/2020')):\n",
    "    #20년도 데이터 안에 이미 데이터가 있으면 넘어가고 없으면 기본값으로 추가\n",
    "    if not 'data' + csvF[-10:-4] in data2020.keys():\n",
    "        data2020.setdefault('data' + csvF[-10:-4])\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    #인코딩 부분에서 문제가 있는 경우가 있어서 기본값 utf-8로 처리에 에러가 있을경우 euc-kr로 대체\n",
    "    try:\n",
    "        data = pd.read_csv('./seoul_subway_data/2020/' + csvF,encoding = 'UTF-8')\n",
    "    except:\n",
    "        data = pd.read_csv('./seoul_subway_data/2020/' + csvF,encoding = 'EUC-KR')\n",
    "    data2020['data' + csvF[-10:-4]] = data\n",
    "\n",
    "#2019년 데이터에서 불필요한 데이터 조정\n",
    "for dataY in data2019.keys():\n",
    "    if '역ID' in data2019[dataY].columns:\n",
    "        data2019[dataY].drop('등록일자',axis=1,inplace = True)\n",
    "        data2019[dataY].rename(columns = {'하차총승객수' : '등록일자'},inplace = True)\n",
    "        data2019[dataY].rename(columns = {'승차총승객수' : '하차총승객수'},inplace = True)\n",
    "        data2019[dataY].rename(columns = {'역명' : '승차총승객수'},inplace = True)\n",
    "        data2019[dataY].rename(columns = {'역ID' : '역명'},inplace = True)\n",
    "    else:\n",
    "        data2019[dataY].dropna(inplace=True)\n",
    "\n",
    "#2020년 데이터에서 불필요한 데이터 조정\n",
    "for dataY in data2020.keys():\n",
    "    if '역ID' in data2020[dataY].columns:\n",
    "        data2020[dataY].drop('등록일자',axis=1,inplace = True)\n",
    "        data2020[dataY].rename(columns = {'하차총승객수' : '등록일자'},inplace = True)\n",
    "        data2020[dataY].rename(columns = {'승차총승객수' : '하차총승객수'},inplace = True)\n",
    "        data2020[dataY].rename(columns = {'역명' : '승차총승객수'},inplace = True)\n",
    "        data2020[dataY].rename(columns = {'역ID' : '역명'},inplace = True)\n",
    "    else:\n",
    "        data2020[dataY].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "js_env",
   "language": "python",
   "name": "js_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
